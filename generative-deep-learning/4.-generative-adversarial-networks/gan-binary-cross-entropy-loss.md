# GAN binary cross entropy loss

* The goal of the generator is to produce data that is so realistic that the discriminator classifies it as real (i.e., it outputs a value close to 1). This means that, for any given fake data point G(z), the generator wants D(G(z)) to be as close to 1 as possible.
* L G ​ =−E z∼p z ​ (z) ​ \[logD(G(z))]
* z is the input to the generator, sampled from a latent space (typically random noise).
* G(z) is the fake data generated by the generator.
* D(G(z)) is the discriminator’s output for this generated data.
* E is the expectation (average) over all samples.
* The generator’s goal is to maximize D(G(z)), meaning it wants D(G(z)) to approach 1 (the discriminator thinks the fake data is real). Since we typically minimize a loss function, the loss is written with a negative sign so that minimizing​ will effectively maximize D(G(z)).
